1
00:00:00,000 --> 00:00:03,178
In the last video, I told you how we can
use the

2
00:00:05,363 --> 00:00:08,541
additive-increase, multiplicative-decrease
method to modulate the size of the TCP

3
00:00:08,541 --> 00:00:12,316
sliding window,
And therefore, control the number of bytes

4
00:00:12,316 --> 00:00:17,149
that are outstanding in the network.
If we want to increase the, the number of

5
00:00:17,149 --> 00:00:21,092
bytes that are outstanding, we might
contribute to more congestion.

6
00:00:21,092 --> 00:00:25,871
If there is congestion and we want to
reduce it, then we might reduce the number

7
00:00:25,871 --> 00:00:29,396
of outstanding bytes,
In other words, reduce the window size.

8
00:00:29,396 --> 00:00:34,234
So using this window size modulation, we
can vary the number of outstanding bytes

9
00:00:34,234 --> 00:00:38,536
and therefore affect or control the amount
of congestion in the network.

10
00:00:38,536 --> 00:00:43,853
Notice this has been done by the end host
only, without any explicit support from

11
00:00:43,853 --> 00:00:47,606
the network.
In order to understand how AIMD works and

12
00:00:47,606 --> 00:00:50,787
then later how TCP congestion control
works,

13
00:00:51,004 --> 00:00:56,498
We're going to start by looking in some
detail at how AIMD works with a single

14
00:00:56,498 --> 00:00:59,285
flow.
If we can understand how it works with a

15
00:00:59,285 --> 00:01:03,663
single flow, then we have a chance of
understanding how it works in a more

16
00:01:03,663 --> 00:01:08,100
complicated network with many, many flows
through a router at the same time.

17
00:01:08,100 --> 00:01:13,872
So, we saw before, AIMD works as follows.
Each time a packet is received okay, we

18
00:01:13,872 --> 00:01:19,145
increase the window by one over W.
Therefore, once we've received the whole

19
00:01:19,145 --> 00:01:23,919
window's worth of packets, the window size
will be increased by one.

20
00:01:23,920 --> 00:01:28,980
Every time a packet is dropped, we're
going to decrease the window size

21
00:01:28,980 --> 00:01:34,216
multiplicatively. We're going to reduce it
by a factor of two and this is the

22
00:01:34,216 --> 00:01:40,182
dynamics that we saw before.
Now let's, look at an animation of the

23
00:01:40,182 --> 00:01:47,125
AIMD process working in practice.
We're going to take a good look at this

24
00:01:47,125 --> 00:01:52,420
animation of a single AIMD flow over a
single bottleneck link.

25
00:01:52,420 --> 00:01:57,784
If we look on the, let me explain what's
going with the figure.

26
00:01:57,784 --> 00:02:04,332
The congestion window size, W, is shown on
the graph down here varying as a function

27
00:02:04,332 --> 00:02:06,620
of time.
So this is cwnd,

28
00:02:06,620 --> 00:02:11,531
The congestion window, and this is the same
as the value here at the source.

29
00:02:11,531 --> 00:02:16,584
So this is the source, this is the
destination, and this is the router in

30
00:02:16,584 --> 00:02:20,092
between.
The router has a buffer and it's going to

31
00:02:20,092 --> 00:02:24,162
buffer packets that are waiting to go onto
the egress link.

32
00:02:24,162 --> 00:02:29,986
The egress link is this one here and this
is the bottleneck link between the source

33
00:02:29,986 --> 00:02:33,325
and the destination.
This link here on the left is running

34
00:02:33,325 --> 00:02:37,960
faster than the link on, on the right,
Which is why every now and again there is

35
00:02:37,960 --> 00:02:41,933
a buildup of packets in this buffer
because they're arriving faster than they

36
00:02:41,933 --> 00:02:44,734
are departing.
The reason that the packets look littler

37
00:02:44,734 --> 00:02:48,911
on the left than they do on the right is
just supposed to represent the fact that

38
00:02:48,911 --> 00:02:52,221
the link on the left is running faster
than the one on the right.

39
00:02:52,221 --> 00:02:55,940
And although, it's at a higher data rate,
and so the packetization delay is, is

40
00:02:55,940 --> 00:03:00,218
shorter and so the packets appear a little
bit shorter on the left.

41
00:03:00,218 --> 00:03:05,071
So packets are going to flow from the
source to the destination, they're the blue

42
00:03:05,071 --> 00:03:09,988
ones, and then for each packet, there is
an acknowledgement coming back to the

43
00:03:09,988 --> 00:03:12,989
source, that's what the red ones are at
the top.

44
00:03:12,989 --> 00:03:17,395
And you can see that the arrival of the
acknowledgements is clocking the, the

45
00:03:17,651 --> 00:03:22,185
transmission of the next packet.
So we often say that an algorithm like

46
00:03:22,185 --> 00:03:26,506
this is self-clocking and we'll see later
the TCP is self-clocking.

47
00:03:26,709 --> 00:03:31,050
The packets are triggered by an
acknowledgement coming back.

48
00:03:31,050 --> 00:03:35,726
Okay, now that I've explained this, I'm
going to restart it so that we can look at

49
00:03:35,726 --> 00:03:40,043
some of the, some of the dynamics.
I'm actually going to give you our URL to

50
00:03:40,043 --> 00:03:44,600
this same animation so you can play around
with this on, on your own time.

51
00:03:44,600 --> 00:03:54,358
So starting again.
We can see that the, that the window size

52
00:03:54,358 --> 00:03:58,911
here is telling us how many packets there
can be outstanding in the network.

53
00:03:58,911 --> 00:04:03,882
And I like to think of it as, that there's
a kind of a bag that is representing the

54
00:04:03,882 --> 00:04:08,075
network as a whole and, we're trying to
figure out how big that bag is.

55
00:04:08,075 --> 00:04:13,106
How many packets can we put into that bag
before they overflow and drop

56
00:04:13,106 --> 00:04:16,161
on the floor?
And I find this a useful way to think

57
00:04:16,161 --> 00:04:19,233
about AIMD.
So, we're basically trying to figure out

58
00:04:19,233 --> 00:04:23,395
where those packets can be and how many
there can be in the link.

59
00:04:23,395 --> 00:04:28,168
And really there's only a couple of two or
three different places that they can be.

60
00:04:28,168 --> 00:04:31,720
First of all, the packets can be on this
link here, on this fixed,

61
00:04:31,720 --> 00:04:35,350
This fixed capacity pipe.
There are a certain number of packets that

62
00:04:35,350 --> 00:04:38,180
we could fit onto that end of
that pipe.

63
00:04:38,180 --> 00:04:42,648
There are a certain number that we could
put here and there are a certain number

64
00:04:42,648 --> 00:04:46,593
that are represented by the
acknowledgements coming in the opposite

65
00:04:46,593 --> 00:04:48,681
direction.
So all of those are fixed.

66
00:04:48,681 --> 00:04:53,438
The only variable portion is how many that
we have currently got in the buffer, in

67
00:04:53,438 --> 00:04:55,585
the middle.
So it's like a concertina.

68
00:04:55,585 --> 00:05:00,139
There's this concertina, to start
with, that concertina is closed and we're

69
00:05:00,139 --> 00:05:05,138
putting the packets into the network and
then as we, as we fill up the links after

70
00:05:05,138 --> 00:05:10,015
the links are full, the only place they
can go is into the buffer, and the buffer

71
00:05:10,015 --> 00:05:13,185
will absorb.
For every extra window, every extra time

72
00:05:13,185 --> 00:05:17,575
that we open the window, we are
essentially putting an extra packet into

73
00:05:17,575 --> 00:05:21,111
that packet buffer.
So initially, when the window is at its

74
00:05:21,111 --> 00:05:24,464
minimum value,
All the links are full, but the buffer is

75
00:05:24,464 --> 00:05:27,387
empty.
If we increase the window by size one, The

76
00:05:27,387 --> 00:05:31,041
links are full, so it can't be placed into
the, into the link.

77
00:05:31,041 --> 00:05:34,452
The only place that it can be placed is
into the buffer.

78
00:05:34,452 --> 00:05:38,898
So the buffer will increase by one.
If we then increase the window by one

79
00:05:38,898 --> 00:05:43,161
again, it'll go into the buffer.
Increase it by one again, it'll go into

80
00:05:43,161 --> 00:05:45,780
the buffer.
Eventually, the buffer overflows.

81
00:05:45,780 --> 00:05:51,277
We drop a packet, and then the AIMD
rules are that we drop the outstanding

82
00:05:51,277 --> 00:05:56,706
window size by half. Eventually the buffer
will go empty again, and then we start

83
00:05:56,706 --> 00:05:59,963
again.
So really, all we're doing by changing the

84
00:05:59,963 --> 00:06:04,850
window size is modulating the occupancy of
the buffer at the bottleneck.

85
00:06:04,850 --> 00:06:09,721
If we look here on the simulation, we can
see that, we can see that happening.

86
00:06:09,721 --> 00:06:14,977
So, right now, the window size is nine, so
that we will see at any instant, there are

87
00:06:14,977 --> 00:06:18,887
nine packets and acknowledgements
outstanding in the network.

88
00:06:18,887 --> 00:06:23,886
But because the links are full, this
outgoing link here is full, our bottleneck

89
00:06:23,886 --> 00:06:27,159
link is full,
The only place that those packets can go

90
00:06:27,159 --> 00:06:30,728
once we increase the window size, is here.
So we filled it up.

91
00:06:30,728 --> 00:06:35,606
Any additional ones are inside the buffer.
And every now and again you'll see that

92
00:06:35,606 --> 00:06:40,425
we're received a full window's worth and
then we increase the, there we go, we will

93
00:06:40,425 --> 00:06:43,990
increase the windows size by one.
It's currently at thirteen.

94
00:06:43,994 --> 00:06:48,991
In a moment it will increase to fourteen.
And every time we increase the window size

95
00:06:48,991 --> 00:06:51,550
the buffer will have one more packet in
it.

96
00:06:51,550 --> 00:06:57,502
And down here, you can see that, every
time we, we receive a full window's worth,

97
00:06:57,502 --> 00:07:03,014
It will actually go up by one and
therefore, that's how the window is going

98
00:07:03,014 --> 00:07:07,644
to evolve over time.
So we're almost getting to the point where

99
00:07:07,644 --> 00:07:12,127
the buffer is full.
We got to a point where, the, the window

100
00:07:12,127 --> 00:07:13,230
is sixteen.
And.

101
00:07:13,230 --> 00:07:17,825
At the moment, the rate at which packets
are coming in is exactly matching the rate

102
00:07:17,825 --> 00:07:21,368
at which they're going out.
In a moment, we're going to actually put

103
00:07:21,368 --> 00:07:24,745
one extra packet into the network and you
see it got dropped.

104
00:07:24,745 --> 00:07:28,399
And the knowledge of that drop is
propagating through the network.

105
00:07:28,399 --> 00:07:32,662
It will now go onto the outgoing link.
It will come back, actually through the

106
00:07:32,662 --> 00:07:35,762
absence of an acknowledgement, but that
doesn't matter.

107
00:07:35,762 --> 00:07:38,420
And so, therefore, the window size will be
halved,

108
00:07:38,420 --> 00:07:41,410
So that's what's going on over here.
The buffer will have,

109
00:07:41,410 --> 00:07:46,740
Will drain because we're only allowed to
have half as many outstanding packets in

110
00:07:46,740 --> 00:07:49,180
the network,
Therefore we stop sending.

111
00:07:49,180 --> 00:07:54,318
The, the buffer drained, because it drains
at the full rate and then we start the

112
00:07:54,318 --> 00:07:59,247
whole process off again.
The first thing I want you to notice is

113
00:07:59,247 --> 00:08:02,246
that the outgoing link is kept busy all
the time,

114
00:08:02,246 --> 00:08:07,080
100% of the time, even though this window
process is concertinaing, it's going full

115
00:08:07,080 --> 00:08:11,302
up and then full down, when we have a
drop, full up and then full down.

116
00:08:11,302 --> 00:08:15,953
So even though this window is going
through this sawtooth motion, the egress,

117
00:08:15,953 --> 00:08:19,870
the bottleneck link in the network is
staying busy all the time.

118
00:08:19,870 --> 00:08:24,598
In other words, the rate at which packets
are being sent is staying constant and

119
00:08:24,598 --> 00:08:29,089
this is a really important property of
AIMD, particularly with a single link.

120
00:08:29,089 --> 00:08:33,404
It's not really adjusting the rate.
It's actually effecting the number of

121
00:08:33,404 --> 00:08:36,359
packets that can be outstanding in, in the
network.

122
00:08:36,359 --> 00:08:41,264
And this subtle distinction will become
very important in a moment when I tell you

123
00:08:41,264 --> 00:08:43,865
a little more about the dynamics of, of
AIMD.

124
00:08:43,865 --> 00:08:48,770
And then it'll help us understand what's
going on when there are multiple flows in

125
00:08:48,770 --> 00:08:58,103
the network.
To increase our understanding of what's

126
00:08:58,103 --> 00:09:01,832
going on, let's look at the dynamics of
that single flow.

127
00:09:01,832 --> 00:09:07,292
This is from a simulation in a well known
network simulator called NS, of a single

128
00:09:07,292 --> 00:09:12,153
TCP flow over a bottle neck link.
The graph at the top here is telling us

129
00:09:12,153 --> 00:09:16,548
the evolution of the congestion window or
cwnd like we had before,

130
00:09:16,548 --> 00:09:20,810
That's the red one. the green one is the
RTT, the round trip time.

131
00:09:20,810 --> 00:09:25,086
This red line here is the utilization of
the bottle neck link.

132
00:09:25,086 --> 00:09:28,465
In other words, how busy is that
bottleneck link kept.

133
00:09:28,465 --> 00:09:33,569
And down here is the occupancy of the
buffer and we can see that evolving.

134
00:09:33,569 --> 00:09:38,948
So it's very similar to the simulation
that we, that we just saw, the animation

135
00:09:38,948 --> 00:09:43,224
that we, that we just saw.
So notice that the, the congestion window

136
00:09:43,224 --> 00:09:48,948
is moving in this beautiful sawtooth, but
because every time we put one more packet

137
00:09:48,948 --> 00:09:52,880
into the network, we increase the
occupancy of the buffer.

138
00:09:52,880 --> 00:09:58,373
So every time we increase W, the only
place that an extra packet can go is in

139
00:09:58,373 --> 00:10:02,225
the buffer.
So it's going to move in perfect lock step

140
00:10:02,225 --> 00:10:05,935
with, with cwnd.
But because we are increasing the

141
00:10:05,935 --> 00:10:10,929
occupancy of the buffer we are
increasing the delay the packets

142
00:10:10,929 --> 00:10:16,494
experience as they go through the network.
So therefore, the RTT, the round trip

143
00:10:16,494 --> 00:10:21,131
time, is also going and following the
same, exactly the same shape.

144
00:10:21,131 --> 00:10:24,770
So, cwnd and the RTT actually follow the
same shape.

145
00:10:27,140 --> 00:10:32,988
The consequence of this is, that the
sending rate for a single flow, which we

146
00:10:32,988 --> 00:10:39,375
can define to be the number of, number of
bytes that we send in one window,

147
00:10:39,375 --> 00:10:44,762
divided by the round trip time.
Because the round trip time is varying

148
00:10:44,762 --> 00:10:50,071
with the window size, W over RTT is
actually going to be a constant.

149
00:10:50,071 --> 00:10:54,550
This is actually going to be a constant.
Why is that?

150
00:10:54,550 --> 00:10:59,730
The reason that it's constant is because W
and RTT are moving in lockstep.

151
00:10:59,730 --> 00:11:03,575
They're essentially the same.
And we saw that in the animation.

152
00:11:03,575 --> 00:11:06,161
The egress link was kept busy at all, all
times.

153
00:11:06,161 --> 00:11:10,728
So, we're not really modulating the rate,
in fact we don't want to modulate the rate

154
00:11:10,728 --> 00:11:14,084
when everything is constant and we've only
got a single flow.

155
00:11:14,084 --> 00:11:18,827
We want to keep the outgoing link busy.
All that the window is doing is probing to

156
00:11:18,827 --> 00:11:23,598
see how big the bag is, how many more
bytes we can put into the network without

157
00:11:23,598 --> 00:11:26,981
it overflowing.
And it's constantly probing and changing

158
00:11:26,981 --> 00:11:31,450
that, that window size, just in case the
conditions change and the, the capacity

159
00:11:31,450 --> 00:11:35,860
increases, and therefore, there's more
room in the bag to put more packets.

160
00:11:36,850 --> 00:11:40,788
Just to just to, to label the point a
little,

161
00:11:40,788 --> 00:11:44,175
The window size is going to move like
this.

162
00:11:44,175 --> 00:11:49,531
RTT will move like this in lock-step and
so this rate is a constant.

163
00:11:49,531 --> 00:11:55,912
So, from this we can also make another
observation and that is how big should the

164
00:11:55,912 --> 00:11:59,728
buffer be so that the whole system will
behave correctly.

165
00:11:59,728 --> 00:12:04,403
So we saw last time that the buffer
occupancy was moving in lock-step with a

166
00:12:04,403 --> 00:12:07,724
window size process.
This, this picture down here is

167
00:12:07,724 --> 00:12:11,783
essentially the same as our animation.
A bottleneck link over here,

168
00:12:11,783 --> 00:12:15,658
A link here with a faster rate, the router
buffer between A and B.

169
00:12:15,658 --> 00:12:19,841
So if we would to, to, to look at that
again in, in a simulation,

170
00:12:20,025 --> 00:12:24,269
And look at the, the behavior.
The graph on the, graphs on the left are

171
00:12:24,269 --> 00:12:28,759
the same as the ones we saw before.
And in this case the buffer occupancy

172
00:12:28,759 --> 00:12:33,848
equals RTT times C.
In other words, it's just enough to hold

173
00:12:33,848 --> 00:12:40,183
enough packets that will fit
into the, the, the round trip when the

174
00:12:40,183 --> 00:12:45,283
buffer is empty.
If we were to make the buffer a little bit

175
00:12:45,283 --> 00:12:49,954
smaller, and that's what we're doing here,
So the buffer is smaller,

176
00:12:49,954 --> 00:12:55,899
Then, what happens is, that the buffer,
after it's, after there's been a drop,

177
00:12:55,899 --> 00:13:00,514
which is taking place here.
When the window size decreases and is

178
00:13:00,514 --> 00:13:05,994
halved according to the AIMD rules, the
buffer will fall because we have fewer

179
00:13:05,994 --> 00:13:11,616
outstanding bytes in the, in the network.
Therefore, the source will stop sending

180
00:13:11,616 --> 00:13:16,812
packets, the buffer will drain, but it's
draining and empty for some period.

181
00:13:16,812 --> 00:13:22,719
So if the router buffer is empty, it means
the egress link, our bottleneck link, our

182
00:13:22,719 --> 00:13:28,270
precious resource, is actually not being
used, and so the utilization will drop

183
00:13:28,270 --> 00:13:32,881
from a 100% during that time.
So if we want to prevent this from

184
00:13:32,881 --> 00:13:38,078
happening and have a 100% at all times, we
need to make sure that this doesn't

185
00:13:38,078 --> 00:13:41,021
happen.
Therefore, we need to make sure that the

186
00:13:41,021 --> 00:13:45,842
buffer never goes empty and we need a
behavior like this, from which we need a

187
00:13:45,842 --> 00:13:49,599
buffer of RTT times C.
Now why it's specifically RTT times C,

188
00:13:49,599 --> 00:13:52,291
you'll see in a problem set a little bit
later.

189
00:13:52,291 --> 00:13:57,050
But the basic intuition is, that the
buffer occupancy, the size of the buffer,

190
00:13:57,050 --> 00:14:02,273
Must, from the peak to the trough, must be
the same as the distance from the peak to

191
00:14:02,273 --> 00:14:07,245
the trough here, to be able to ride out
the time when the window size is halved,

192
00:14:07,245 --> 00:14:11,147
and we have fewer outstanding packets
placed into the network.

193
00:14:11,147 --> 00:14:16,320
And that distance there turns out to be
RTT times C and we'll see that later in a

194
00:14:16,320 --> 00:14:20,143
problem set.
Let's summarize what we've learned for a

195
00:14:20,143 --> 00:14:22,840
single flow.
The window is going to, to expand and

196
00:14:22,840 --> 00:14:27,119
contract according to AIMD, the
additive-increase/multiplicative-decrease,

197
00:14:27,119 --> 00:14:32,043
which is going to modulate the size of the
TCP sliding window in order to determine

198
00:14:32,043 --> 00:14:35,267
how many outstanding bytes there can be in
the network.

199
00:14:35,267 --> 00:14:39,898
Essentially, we're probing how many by,
bytes that the pipe can hold from end to

200
00:14:39,898 --> 00:14:42,067
end.
And we're constantly be going to be

201
00:14:42,067 --> 00:14:44,646
probing by changing the size of that
window.

202
00:14:44,646 --> 00:14:48,457
We're going to carefully increase it, see
how much space there is.

203
00:14:48,457 --> 00:14:52,794
If we find that we overfill it, we're
going to drop back down again, and then

204
00:14:52,794 --> 00:14:56,905
we're going to keep trying to probe it to
see if there's more capacity that's

205
00:14:56,905 --> 00:14:59,593
available.
So, we're going to tentatively, additively

206
00:14:59,593 --> 00:15:03,652
increase and then if we find that we've
got into trouble, we're going to very

207
00:15:03,652 --> 00:15:07,816
quickly in a very responsive way, drop
back down again to be able to reduce the

208
00:15:07,816 --> 00:15:11,190
number of outstanding bytes in the network
as quickly as we can.

209
00:15:11,190 --> 00:15:15,985
So the sawtooth, sawtooth is actually the
stable operating point of TCP.

210
00:15:15,985 --> 00:15:19,971
There's nothing out of control just cause
it's oscillating.

211
00:15:19,971 --> 00:15:24,970
It's exactly the behavior that we want
under a stable operating condition.

212
00:15:24,970 --> 00:15:29,066
And, the sending rate is, in fact,
constant, so long as we have enough

213
00:15:29,066 --> 00:15:31,641
buffers in the network, which is RTT times
C.

214
00:15:31,641 --> 00:15:34,684
So these are all the observations for a
single flow.

215
00:15:34,684 --> 00:15:39,365
In the next video, we're going to see how
things are a little bit different when we

216
00:15:39,365 --> 00:15:41,180
have many flows in the network.

