1
00:00:00,000 --> 00:00:04,415
In this video I am going to start out by
telling you some of the shortcomings of a

2
00:00:04,415 --> 00:00:08,002
FIFO output queue and, some of the
problems it causes.

3
00:00:08,002 --> 00:00:10,058
And I am going to describe two
alternatives.

4
00:00:10,240 --> 00:00:15,036
Switches that provide, strict priorities
to give high priority and low priority

5
00:00:15,036 --> 00:00:19,042
traffic and those who can give a
guaranteed rate to each of the flows

6
00:00:19,043 --> 00:00:23,032
passing through it.
Let's start by reviewing what an output

7
00:00:23,032 --> 00:00:27,041
queued packet switch looks like.
This is an example we saw before where we

8
00:00:27,041 --> 00:00:31,038
had three packets arriving.
Their addresses will be looked up and they

9
00:00:31,038 --> 00:00:35,092
will be switched to the correct output.
In this particular case two red packets.

10
00:00:35,092 --> 00:00:38,041
Meaning they'll go to the middle red
output.

11
00:00:38,041 --> 00:00:41,767
And, blue one to the top.
One of the red packets gets to go.

12
00:00:41,767 --> 00:00:46,099
The other one is held back waiting for the
link to be free, and then it goes an it's

13
00:00:46,099 --> 00:00:50,018
way, afterwards.
So, implicit here is the, the assumption

14
00:00:50,018 --> 00:00:54,050
that the, the output queue is a FIFO,
first in first out, and that's pretty,

15
00:00:54,050 --> 00:00:57,058
pretty reasonable assumption for most
router queues.

16
00:00:57,058 --> 00:01:00,018
But in what are we going to be looking at
next.

17
00:01:00,018 --> 00:01:04,056
We are gonna be focusing on this output
queue and seeing what some of the

18
00:01:04,056 --> 00:01:09,635
consequences are, of it being a FIFO.
So, a FIFO queue is sometimes called a

19
00:01:09,635 --> 00:01:13,057
free for all queue.
If there are many packets flowing through

20
00:01:13,057 --> 00:01:16,015
this queue coming from the different
inputs.

21
00:01:16,015 --> 00:01:20,445
So, I've drawn here three inputs to the
queue, representing the three inputs to

22
00:01:20,445 --> 00:01:24,078
the other inputs to the switch.
So, these are all packets that are coming

23
00:01:24,078 --> 00:01:28,059
through that are part of flows that are
going to this one output.

24
00:01:28,059 --> 00:01:32,081
So we'll see packets coming out of here,
coming from all of those inputs.

25
00:01:32,081 --> 00:01:37,050
And presumably, at any one time, when we
have congestion, we'll see packets queued

26
00:01:37,050 --> 00:01:41,041
up in this, FIFO queue.
If there are many flows passing through

27
00:01:41,041 --> 00:01:44,010
the queue.
Whoever sends at the highest rate.

28
00:01:44,010 --> 00:01:48,087
Whoever sends the most packets will, in
fact, receive the highest usage of this

29
00:01:48,087 --> 00:01:52,010
output link.
So, in other words, if this one up here is

30
00:01:52,010 --> 00:01:54,092
able to get a whole load of packets into
here.

31
00:01:54,092 --> 00:02:00,011
While this one down here, this the bottom
input is only able to get a small number.

32
00:02:00,011 --> 00:02:02,098
This guy up here is going to hog this
output link.

33
00:02:02,098 --> 00:02:07,092
So, if there's is a really big hog of a
flow going through, a little flow could

34
00:02:07,092 --> 00:02:11,682
easily get squeezed out completely.
People say that this, this kind of FIFO

35
00:02:11,682 --> 00:02:16,425
queue, while it's nice and simple, it
encourages bad behaviour, because the best

36
00:02:16,425 --> 00:02:21,595
thing for a flow to do is to try and crowd
out every other flow by sending as fast as

37
00:02:21,595 --> 00:02:24,126
it can.
It would be a little bit like when you're

38
00:02:24,126 --> 00:02:28,608
downloading a web page, the thing to do
would be to try and get your packets sent

39
00:02:28,608 --> 00:02:32,866
towards you at the highest possible rate
to maximise the amount of the, amount of

40
00:02:32,866 --> 00:02:36,506
the queue that you can get.
It's not very friendly behaviour and it

41
00:02:36,506 --> 00:02:39,647
doesn't provide a good incentive for good
behaviour.

42
00:02:39,647 --> 00:02:44,741
Now, imagine that some of the traffic was
very urgent, for example, some control

43
00:02:44,741 --> 00:02:48,008
traffic.
So, let's say we had some, some urgent red

44
00:02:48,008 --> 00:02:52,090
packets here, and then we had some less
urgent green packets elsewhere maybe

45
00:02:52,090 --> 00:02:56,045
there's another one that's squeezed in, in
front of that.

46
00:02:56,045 --> 00:03:01,046
A green packet down here, and a green
packet down here and maybe let's just add

47
00:03:01,046 --> 00:03:05,090
another a red packet for good measure.
So, it these ones were more important.

48
00:03:05,090 --> 00:03:10,082
What the FIFO queue will do is simply send
them out in the order in which they came

49
00:03:10,082 --> 00:03:12,679
in.
So, if we were to number the order in

50
00:03:12,679 --> 00:03:17,623
which they arrived, say this was number
one, this was number two, this was the

51
00:03:17,623 --> 00:03:21,870
third one to arrive, this was the fourth
one, this was the fifth one, and the sixth

52
00:03:21,870 --> 00:03:24,675
one.
They're obviously just going to go out in

53
00:03:24,675 --> 00:03:27,976
that order of one, two, three, four, five,
six on the outgoing line.

54
00:03:27,976 --> 00:03:32,669
So, not very good for the urgent control
traffic or perhaps it's some important

55
00:03:32,669 --> 00:03:35,078
video traffic.
So, the FIFO doesn't have any way to

56
00:03:35,078 --> 00:03:38,888
distinguish important.
It just says, if you got here first, and

57
00:03:38,888 --> 00:03:42,044
there was room in the queue, you are the
most important packet.

58
00:03:42,044 --> 00:03:48,003
So, we can't say anything meaningful about
the rate of each flow sharing this queue.

59
00:03:48,003 --> 00:03:52,570
One little observation that's going to
prove useful later, and it's why I've

60
00:03:52,570 --> 00:03:55,396
labeled this as the size of the queue as
B.

61
00:03:55,396 --> 00:03:59,374
And the rate at which it's being served,
the outgoing link R.

62
00:03:59,374 --> 00:04:02,884
Notice that if a packet does make in into
the queue.

63
00:04:02,884 --> 00:04:08,574
So, if I have a packet that does make it
into the queue, let's say this one ends up

64
00:04:08,574 --> 00:04:12,947
at the tail of the queue.
The maximum time it has to wait is B over

65
00:04:12,947 --> 00:04:13,551
R.
Alright.

66
00:04:13,551 --> 00:04:18,024
So the delay through that queue we know is
less than or equal to B over R.

67
00:04:18,024 --> 00:04:22,323
So, we're going to remember this.
We're going to use this observation later.

68
00:04:22,323 --> 00:04:25,703
In this video.
I'm gonna describe two alternatives to

69
00:04:25,703 --> 00:04:29,665
simple FIFO queuing.
The first one is called Strict Priorities

70
00:04:29,665 --> 00:04:33,011
where we give higher priority to some
flows over others.

71
00:04:33,011 --> 00:04:37,434
And the second one is Rate Guarantees
where we give a guaranteed rate or a

72
00:04:37,434 --> 00:04:41,034
guaranteed fraction of the outgoing link
to each of the flows.

73
00:04:41,034 --> 00:04:45,068
So, basically we're going to take our
single FIFO that we had before and replace

74
00:04:45,068 --> 00:04:50,086
it with a more complicated mechanism here.
We simply replaced it with a high priority

75
00:04:50,086 --> 00:04:53,743
queue and a low priority queue.
So, the inputs are just the same as

76
00:04:53,743 --> 00:04:56,058
before.
These are where packets arrive from the

77
00:04:56,058 --> 00:04:58,960
incoming links.
But now, as a packet arrives, we're gonna

78
00:04:58,960 --> 00:05:04,014
decide whether we're to place it into the
high priority queue or into a low priority

79
00:05:04,014 --> 00:05:06,792
queue and we do this based on bits in the
header.

80
00:05:06,792 --> 00:05:10,878
So, when a packet arrives it might have a
bit in the header and in IP there's a

81
00:05:10,878 --> 00:05:14,455
specific field for this.
It's called the type of service field.

82
00:05:14,455 --> 00:05:19,535
And, we might use that to decide which
traffic is high priority and which is low

83
00:05:19,535 --> 00:05:22,905
priority.
We might do this for example to say that

84
00:05:22,905 --> 00:05:25,691
video traffic is more important that
email.

85
00:05:25,691 --> 00:05:30,854
So, we might want to put the video in the
high priority queue, and the email in the

86
00:05:30,854 --> 00:05:34,714
low priority queue.
Or we might say that control traffic is

87
00:05:34,714 --> 00:05:39,829
more important that data, because we
always want to have high priority for the

88
00:05:39,829 --> 00:05:44,655
management traffic on the network.
Or an operator might say that their gold

89
00:05:44,655 --> 00:05:49,606
users, that their traffic takes strict
preference over their silver, customers.

90
00:05:49,606 --> 00:05:54,733
And so, that's a way of classifying users
and giving preference to those who pay

91
00:05:54,733 --> 00:05:58,575
more.
The way that this actually works is, when

92
00:05:58,575 --> 00:06:03,371
the packets arrive so they would be
placed, and I'm going to put, I'm going to

93
00:06:03,371 --> 00:06:08,392
put the red packets in here and I'm going
to put green packets in here for lower

94
00:06:08,392 --> 00:06:11,050
priority.
The basic discipline is, is this.

95
00:06:11,050 --> 00:06:14,046
There's a scheduler that sits at the
output here.

96
00:06:14,046 --> 00:06:19,023
And it's always going to take packets from
the high priority if they are there.

97
00:06:19,023 --> 00:06:23,088
And it's only going to serve the low
priority if there's nothing in the high

98
00:06:23,088 --> 00:06:27,009
priority queue.
The consequence is that high priority

99
00:06:27,009 --> 00:06:29,081
traffic doesn't see the low priority
traffic.

100
00:06:29,081 --> 00:06:33,050
It's unaffected by it.
Because we only serve the low priority

101
00:06:33,050 --> 00:06:38,015
queue if the high priority queue is empty.
It's as if the high priority traffic has

102
00:06:38,015 --> 00:06:41,087
its own private network, and doesn't see
the low priority traffic at all.

103
00:06:41,087 --> 00:06:45,085
This is great for many types of, of many
occasions where we want to give strict

104
00:06:45,085 --> 00:06:49,057
preference to, to another one.
But it does run the danger of starving out

105
00:06:49,057 --> 00:06:52,083
the low priority traffic.
So, you can only use it when there's a

106
00:06:52,083 --> 00:06:55,062
reasonably small amount of high, high
priority traffic.

107
00:06:55,062 --> 00:06:59,075
We don't want to completely hog the, hog
the link, and starve out this low priority

108
00:06:59,075 --> 00:07:01,642
traffic at all.
But it is quite widely used and many

109
00:07:01,642 --> 00:07:05,033
switchers and routers support this, the
capability today.

110
00:07:05,033 --> 00:07:11,006
What if instead of strict priorities, we
wanted to have weighted priorities?

111
00:07:11,006 --> 00:07:15,079
What I mean by that is, if a packet
arrives into this queue here.

112
00:07:15,079 --> 00:07:22,031
And packets arrive into this queue here.
I want the, the, in, in, in some sense for

113
00:07:22,031 --> 00:07:26,097
the traffic here to be considered to be
twice as important as this here.

114
00:07:26,097 --> 00:07:32,028
Not, not always have a strict preference
but having twice as many opportunities to

115
00:07:32,028 --> 00:07:35,063
send.
More precisely, I'm going to say that the

116
00:07:35,063 --> 00:07:40,071
rate at which this queue served, is going
to be two over two plus one.

117
00:07:40,071 --> 00:07:46,010
So, in other words, two is a fraction of
the total rate of the egress link.

118
00:07:46,010 --> 00:07:51,092
Likewise, I'm going to say that the rate
that this one is going to be served is

119
00:07:51,092 --> 00:07:55,009
one.
That's its weight, divided by the total

120
00:07:55,009 --> 00:07:58,015
weight, times the outgoing link rate.
Okay.

121
00:07:58,015 --> 00:08:04,020
That's what I'm trying to accomplish.
I can generalize this to, many queues, as

122
00:08:04,020 --> 00:08:08,023
follows.
This is simply just, just increasing it

123
00:08:08,023 --> 00:08:13,084
from two to n, where Q sub i.
Is going to receive W sub i bits, of

124
00:08:13,084 --> 00:08:18,080
service.
And that's the, that, that, that's its,

125
00:08:18,080 --> 00:08:23,455
its weight.
So for example, W1 here will have a rate

126
00:08:23,455 --> 00:08:30,376
R1, is W1 divided by the sum of all of
the weights, alright that is the sum

127
00:08:30,376 --> 00:08:36,085
over I have Wi times R.
All the way down to of course, W sub n,

128
00:08:39,086 --> 00:08:40,971
just as before R of n equals W of n over
the sum.

129
00:08:40,971 --> 00:08:43,703
I'll just write it like that, times R of
the outgoing link.

130
00:08:43,703 --> 00:08:49,503
If all the packets were of the same length
this would actually be pretty easy.

131
00:08:49,795 --> 00:08:56,763
We would simply visit each of the queues
in turn, and we will call that a round.

132
00:08:56,763 --> 00:09:01,233
So, one round is when we visited all of
the queues in turn.

133
00:09:01,233 --> 00:09:07,712
And then we would send W sub i units.
So, they could be bits or complete packets

134
00:09:07,712 --> 00:09:13,002
from each queue in each round.
So, on the outgoing line, we could have,

135
00:09:13,002 --> 00:09:17,094
we could have W sub one bits from here.
Then we would have all the way through to

136
00:09:17,094 --> 00:09:22,080
W sub n bits from this one and then all
the intervening queues as well, and so

137
00:09:22,080 --> 00:09:26,012
this would be a round, when we visited
over the queues.

138
00:09:26,012 --> 00:09:31,004
And, you can see that the proportion that
each queue has, has been served in that

139
00:09:31,004 --> 00:09:35,035
round is in proportion to the weights,
which is exactly what we wanted.

140
00:09:35,035 --> 00:09:39,083
So, if we could serve the packets as bits
at a time and actually send them out as

141
00:09:39,083 --> 00:09:43,098
bits at a time, which of course we can't.
But if we could, then this would be

142
00:09:43,098 --> 00:09:46,074
actually pretty easy to accomplish what we
wanted.

143
00:09:46,074 --> 00:09:51,023
We would simply classify the packets as
they arrive into the queue that they are

144
00:09:51,023 --> 00:09:54,091
destined for.
And then we would serve those queues

145
00:09:54,091 --> 00:10:00,164
according to, the W sub i bits in each
round and then send them out.

146
00:10:00,164 --> 00:10:06,589
Of course, packets are variable length and
they don't consist of single bits.

147
00:10:06,589 --> 00:10:12,004
And the problem is that real packets vary
in size from something like 64 bytes all

148
00:10:12,004 --> 00:10:15,677
the way to, in, in the case of ethernet
about 1500 bytes.

149
00:10:15,677 --> 00:10:20,553
There are jumbo frames that are even
longer than this but even, even here we've

150
00:10:20,553 --> 00:10:23,772
got two orders of magnitude difference in
packet size.

151
00:10:23,772 --> 00:10:28,560
So, if we were to serve this packet-by-
packet instead of bit by bit it would

152
00:10:28,560 --> 00:10:33,837
really mess up the, the weights and we
wouldn't accomplish what we were trying to

153
00:10:33,837 --> 00:10:36,405
do.
Clearly, we must take into account the

154
00:10:36,405 --> 00:10:41,561
packet lengths if we want to prevent long
packets from crowding out the short ones.

155
00:10:41,561 --> 00:10:44,094
So, let me describe how we, how we do
this.

156
00:10:44,094 --> 00:10:50,003
I'm going to first describe it in terms of
a kind of a thought experiment.

157
00:10:50,003 --> 00:10:55,068
I'm going to use this notion of rounds
again where we visit each queue in turn in

158
00:10:55,068 --> 00:10:59,091
a round.
And then we're going to send W sub i bits

159
00:10:59,091 --> 00:11:04,763
from each queue during that round.
But I am going to assume that in addition to

160
00:11:04,763 --> 00:11:08,059
the, the queues that I have here that I
have another.

161
00:11:08,059 --> 00:11:13,112
I'm going to call it a magic queue.
Just to remind us this really isn't a

162
00:11:13,112 --> 00:11:17,002
queue.
It's just going to be a processing element

163
00:11:17,002 --> 00:11:22,058
just to have us think about the problem.
We're going to get rid of this in a, in a

164
00:11:22,058 --> 00:11:25,605
minute.
So in a round, the first queue gets to

165
00:11:25,605 --> 00:11:29,077
send W sub one bits and the last queue
gets to send W n bits.

166
00:11:29,077 --> 00:11:35,017
What we're going to do is, we're going to
imagine that we're going to serve each of

167
00:11:35,017 --> 00:11:38,053
these queues by that number of bits in
each round.

168
00:11:38,053 --> 00:11:43,048
And then when we get to an end-of-packet
marker, which is the last bit in, the last

169
00:11:43,048 --> 00:11:46,092
bit in a packet.
So, this would be the end-of-packet here,

170
00:11:46,092 --> 00:11:49,094
and then let's say this is the
end-of-packet here.

171
00:11:49,094 --> 00:11:54,071
Once we've got to that end-of-packet
marker we will construct complete packets

172
00:11:54,071 --> 00:11:58,879
and send them on to the outgoing links.
So, that's what this magic queue is going

173
00:11:58,879 --> 00:12:02,026
to do.
It's going to turn those bit by bit into

174
00:12:02,026 --> 00:12:05,082
packet-by-packet.
And so this will be the end-of-packet bit

175
00:12:05,082 --> 00:12:08,048
here, and this is the end-of-packet bit
here.

176
00:12:08,048 --> 00:12:12,090
But this is, this is recognizing the we
can't send them out in bits.

177
00:12:12,090 --> 00:12:17,020
We wait until the full packet is
accumulated, and then send them out.

178
00:12:17,020 --> 00:12:22,019
So, the question is, in what order should
we be sending these out on to the line?

179
00:12:22,019 --> 00:12:26,015
When should we send them?
Because our goal is to meet the rate

180
00:12:26,015 --> 00:12:30,716
guarantees where each queue gets that
weighted fair share of the outgoing line.

181
00:12:30,716 --> 00:12:35,192
So, in what order should we send those
packets in order to accomplish that?

182
00:12:35,192 --> 00:12:40,527
I'm going to describe that next.
So, just as before, we're going to assume

183
00:12:40,527 --> 00:12:45,866
that time proceeds in rounds.
So, our unit of time is going to be

184
00:12:45,866 --> 00:12:49,764
rounds.
And we're going to figure out, if we were

185
00:12:49,764 --> 00:12:55,088
to service the packets bit by bit.
Which round would they have finished in.

186
00:12:55,088 --> 00:12:59,045
Okay?
So, if we were to serve them bit by bit,

187
00:12:59,045 --> 00:13:05,060
which round would they have finished in?
Well, I'm going to start by making an, an

188
00:13:05,060 --> 00:13:10,093
observation that will give you a, give you
a clue as to how we're going to use this.

189
00:13:10,093 --> 00:13:14,014
Let's consider a packet here that's
waiting to go.

190
00:13:14,014 --> 00:13:18,069
And let's consider the round in which it
starts, we'll call that S of k.

191
00:13:18,069 --> 00:13:22,074
And the round in which it finishes, and
we'll call that F sub k.

192
00:13:22,074 --> 00:13:29,024
Because we're serving everything, in
rounds, and time progresses in rounds, we

193
00:13:29,024 --> 00:13:35,099
can say the finishing time of this packet
is its starting time in rounds plus the

194
00:13:35,099 --> 00:13:41,492
length of the packet divided by w of one.
That's because that first queue will

195
00:13:41,492 --> 00:13:45,005
receive exactly W sub one bits of service
in each round.

196
00:13:45,005 --> 00:13:49,049
So, it's finishing round is its starting
round plus its length divided by the

197
00:13:49,049 --> 00:13:52,012
number of bits it gets served per round.
Okay.

198
00:13:52,012 --> 00:13:56,078
So, this is the finishing time here.
Now, let's think about what happens when a

199
00:13:56,078 --> 00:14:00,021
packet arrives.
So, we're going to try and calculate the

200
00:14:00,021 --> 00:14:03,001
starting time of that packet when it
arrives.

201
00:14:03,001 --> 00:14:07,075
In other words, what time will it enter
service and what time will it finish

202
00:14:07,075 --> 00:14:10,092
service.
It might be surprising that we can do this

203
00:14:10,092 --> 00:14:16,003
but I'm going to show you a way we can
calculate both it's starting time and it's

204
00:14:16,003 --> 00:14:20,056
finishing time, when it arrives.
So, the, the starting time of that packet,

205
00:14:20,056 --> 00:14:24,679
the time at which it starts to enter
service, is going to depend on what's

206
00:14:24,679 --> 00:14:28,410
ahead of it in the queue.
So, if we're keeping track of the

207
00:14:28,410 --> 00:14:33,578
finishing time of this packet, in rounds
and we want to know what the starting time

208
00:14:33,578 --> 00:14:36,665
of this next packet here and its finishing
time.

209
00:14:36,665 --> 00:14:41,628
We can do the following calculations.
So, this is the finishing time of the k-1

210
00:14:41,628 --> 00:14:44,675
packet.
Its the one that's ahead of waiting in

211
00:14:44,675 --> 00:14:47,764
queue.
We can say that the starting time of the

212
00:14:47,764 --> 00:14:52,496
packet k is going to be simply the
finishing time of the packet ahead of it

213
00:14:52,496 --> 00:14:55,011
because
It, we were proceeding in rounds, so it

214
00:14:55,011 --> 00:14:59,544
will be immediately entering service as
soon as the one ahead of it is finished.

215
00:14:59,544 --> 00:15:04,527
Unless the queue happens to be empty and
there's nothing ahead of us, in which case

216
00:15:04,527 --> 00:15:08,596
it will enter service now.
There's going to be the max of these two

217
00:15:08,596 --> 00:15:11,325
values.
The max of the finishing time of the

218
00:15:11,325 --> 00:15:15,535
packet ahead of it and now.
The second thing that we can say is that

219
00:15:15,535 --> 00:15:20,402
the finishing time of K is it's starting
time plus L over W1, just as before

220
00:15:20,402 --> 00:15:26,232
because we know that's how much service.
So, the combination of these two gives us

221
00:15:26,232 --> 00:15:31,691
a recursion that so long as we keep
calculating the finishing time and keep

222
00:15:31,691 --> 00:15:36,586
track of that, we can calculate the
starting time and the finishing time of

223
00:15:36,586 --> 00:15:39,959
packets as they arrive.
Those are pretty neat property.

224
00:15:39,959 --> 00:15:43,975
And then what we're going to do is, we're
going to service the packets.

225
00:15:43,975 --> 00:15:47,080
In other words, we're going to take the
packets from head of lines.

226
00:15:47,080 --> 00:15:51,278
So, here is the scheduler.
Its going to be examining the head of line

227
00:15:51,278 --> 00:15:55,716
packets, and its going to pick the one
with the lowest F, the lowest finishing

228
00:15:55,716 --> 00:15:57,882
time.
So, it will pick the packet with the

229
00:15:57,882 --> 00:16:00,693
lowest finishing time.
So, that's what the scheduler does.

230
00:16:00,693 --> 00:16:03,293
So we, calculated the F of K when the
packet came in.

231
00:16:03,293 --> 00:16:08,362
And then, when it gets to the of head of
line, it's competing with all the head of

232
00:16:08,362 --> 00:16:13,140
line packets to leave, and the scheduler
is simply gonna pick the one with lowest

233
00:16:13,140 --> 00:16:16,114
finishing time.
This has the nice property that finishing

234
00:16:16,114 --> 00:16:18,588
times can be determined when the packet
arrives.

235
00:16:18,588 --> 00:16:22,917
And, the packets are served in order of
their finishing time which at least

236
00:16:22,917 --> 00:16:25,211
intuitively seems like the best thing to
do.

237
00:16:25,211 --> 00:16:30,026
It turns out that it is more intui-, more
than just intuitively a good thing to do.

238
00:16:30,026 --> 00:16:33,024
I'll show you why it actually is the right
thing to do.

239
00:16:34,041 --> 00:16:39,022
If we plot the finishing time of the
packets, if they were being served bit by

240
00:16:39,022 --> 00:16:41,093
bit.
In other words, the time that the end of

241
00:16:41,093 --> 00:16:46,055
packet bit would leave on the outgoing
line if the packet was being served.

242
00:16:46,055 --> 00:16:51,333
But it might look something like this.
This is just something I sketched.

243
00:16:51,333 --> 00:16:56,509
If we look at the finishing time of the
packet-by-packet scheme, where each packet

244
00:16:56,509 --> 00:17:01,534
goes and must wait for the packet ahead of
it to finish before it can go on the line.

245
00:17:01,534 --> 00:17:06,131
Packets could end up actually departing a
little bit later, because they could be

246
00:17:06,131 --> 00:17:08,554
held up by a packet that's still in
service.

247
00:17:08,554 --> 00:17:13,401
So, there could be a little bit of a delta
between when the packet would finish

248
00:17:13,401 --> 00:17:18,464
bit-by-bit, and we know if it's bit-by-bit
then the rate it will receive, the, the,

249
00:17:18,464 --> 00:17:22,573
the, the Qi will receive, will be W sub i
over the sum of the Wj's.

250
00:17:22,573 --> 00:17:27,110
In other words, the weight that we're
looking for of the out going line.

251
00:17:27,109 --> 00:17:31,092
So, if this was being met then we know
that would be true.

252
00:17:31,092 --> 00:17:37,003
In the packet-by-packet scheme, it can be
proved there the difference in the time

253
00:17:37,003 --> 00:17:42,225
that it will depart under the packet-by-
packet scheme is no more than Lmax.

254
00:17:42,225 --> 00:17:47,245
The maximum length packet divided by R
later than under the bit-by-bit scheme.

255
00:17:47,245 --> 00:17:50,943
And that's true for every single packet in
the system.

256
00:17:50,943 --> 00:17:57,068
So, this is really useful because over a
long period of time this tells us that the

257
00:17:57,068 --> 00:18:01,450
same number of bits will have departed as
under the bit -by-bit scheme.

258
00:18:01,450 --> 00:18:03,792
That will just be jiggled around a little
bit.

259
00:18:03,792 --> 00:18:09,662
There will be a little variance in the
actual departure time but measured over a

260
00:18:09,662 --> 00:18:13,703
long period of time.
So, under this packet-by-packet scheme RF

261
00:18:13,703 --> 00:18:19,039
of i will be the same as it was before.
So it'll be that weight of I divided by

262
00:18:19,039 --> 00:18:23,071
the sum over WJ of R.
So, this will accomplish exactly the rates

263
00:18:23,071 --> 00:18:26,080
that we want.
This scheme is often called WFQ, or

264
00:18:26,080 --> 00:18:31,008
Weighted Fair Queueing.
Weighted Fair Queueing is a pretty famous

265
00:18:31,008 --> 00:18:34,011
technique.
You can find lots of references to it.

266
00:18:34,030 --> 00:18:38,338
And it's also known as packet-by-packet
generalized processor sharing.

267
00:18:38,338 --> 00:18:42,049
But if you look under WFQ, you can find
lots of references to it.

268
00:18:42,049 --> 00:18:47,066
But what it essentially tells us is, tells
us a specific mechanism for calculating

269
00:18:47,066 --> 00:18:52,007
the finishing time of packets and
scheduling them, so that we can give

270
00:18:52,007 --> 00:18:57,024
weighted fairness, weighted usage of the
outgoing link, and rate guarantees to each

271
00:18:57,024 --> 00:19:01,022
of the flows.
In summary, FIFO queues are a bit of a

272
00:19:01,022 --> 00:19:04,032
free for all.
They have no priorities, no guaranteed

273
00:19:04,032 --> 00:19:07,023
rates.
And there's an incentive for a, for a flow

274
00:19:07,023 --> 00:19:12,033
to send as many packets as it can into the
queue, so that it maximizes it's share of

275
00:19:12,033 --> 00:19:15,085
the outgoing links.
So, they kind of encourage bad behavior.

276
00:19:15,085 --> 00:19:19,013
So instead, it's quite common to use
strict priorities.

277
00:19:19,013 --> 00:19:23,049
High priority traffic, could see or
experience a network which appears to have

278
00:19:23,049 --> 00:19:26,046
no low priority traffic at all.
It's unaffected by it.

279
00:19:26,046 --> 00:19:30,094
This is useful if we have limited amounts
of high priority traffic like control

280
00:19:30,094 --> 00:19:33,903
traffic in the network.
But if we want to do something which is

281
00:19:33,903 --> 00:19:38,599
more of a weighted priority, then we need
to use something like weighted fair

282
00:19:38,599 --> 00:19:42,966
queueing, which lets us give each flow a
guaranteed service rate, and we do that by

283
00:19:42,966 --> 00:19:47,017
scheduling the packets in order of their
bit-by-bit finishing times.

284
00:19:47,017 --> 00:19:48,074
That's the end of the video.

